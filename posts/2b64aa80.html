<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>线性判别分析 | ihadu</title><meta name="author" content="ihadu"><meta name="copyright" content="ihadu"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="线性判别分析(Linear Discriminant Analysis) 线性判别分析(Linear Discriminant Analysis)，是一种监督学习(supervised learning)算法。线性判别式分析也叫做Fisher线性判别(Fisher Linear Discriminant ,FLD)，是模式识别的经典算法，它是在1996年由Belhumeur引入模式识别和人工智能领"><meta property="og:type" content="article"><meta property="og:title" content="线性判别分析"><meta property="og:url" content="https://nivbi.com/posts/2b64aa80.html"><meta property="og:site_name" content="ihadu"><meta property="og:description" content="线性判别分析(Linear Discriminant Analysis) 线性判别分析(Linear Discriminant Analysis)，是一种监督学习(supervised learning)算法。线性判别式分析也叫做Fisher线性判别(Fisher Linear Discriminant ,FLD)，是模式识别的经典算法，它是在1996年由Belhumeur引入模式识别和人工智能领"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://oss.kiscloud.net/image/user/anime/Chainsaw/wallhaven-gpjg37_1920x1080.webp"><meta property="article:published_time" content="2023-08-27T10:02:16.000Z"><meta property="article:modified_time" content="2023-08-28T08:20:44.191Z"><meta property="article:author" content="ihadu"><meta property="article:tag" content="降维"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://oss.kiscloud.net/image/user/anime/Chainsaw/wallhaven-gpjg37_1920x1080.webp"><link rel="shortcut icon" href="/images/dog.png"><link rel="canonical" href="https://nivbi.com/posts/2b64aa80.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//hm.baidu.com"><link rel="preconnect" href="//busuanzi.ibruce.info"><meta name="google-site-verification" content="h-TVRSWVCnbA8LDyXZkYIrIJ4pr1OUAgVfR5h2H4Eok"><meta name="baidu-site-verification" content="codeva-V4Yhtugi3b"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/node-snackbar/0.1.16/snackbar.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.19/fancybox/fancybox.min.css" media="print" onload='this.media="all"'><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script"),t=(e.src="https://hm.baidu.com/hm.js?546017bccd857b94cdaba2806f36802a",document.getElementsByTagName("script")[0]);t.parentNode.insertBefore(e,t)}()</script><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"/search.xml",preload:!1,top_n_per_article:1,unescape:!1,languages:{hits_empty:"找不到您查询的内容：${query}",hits_stats:"共找到 ${hits} 篇文章"}},translate:{defaultEncoding:2,translateDelay:0,msgToTraditionalChinese:"繁",msgToSimplifiedChinese:"簡"},noticeOutdate:void 0,highlight:{plugin:"highlighjs",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:!1},copy:{success:"复制成功",error:"复制错误",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!1},runtime:"",dateSuffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:void 0,lightbox:"fancybox",Snackbar:{chs_to_cht:"你已切换为繁体",cht_to_chs:"你已切换为简体",day_to_night:"你已切换为深色模式",night_to_day:"你已切换为浅色模式",bgLight:"#49b1f5",bgDark:"#1f1f1f",position:"bottom-left"},source:{justifiedGallery:{js:"https://cdnjs.cloudflare.com/ajax/libs/flickr-justified-gallery/2.1.2/fjGallery.min.js",css:"https://cdnjs.cloudflare.com/ajax/libs/flickr-justified-gallery/2.1.2/fjGallery.min.css"}},isPhotoFigcaption:!1,islazyload:!1,isAnchor:!1,percent:{toc:!0,rightside:!1},autoDarkmode:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"线性判别分析",isPost:!0,isHome:!1,isHighlightShrink:!0,isToc:!0,postUpdate:"2023-08-28 16:20:44"}</script><noscript><style type="text/css">#nav{opacity:1}.justified-gallery img{opacity:1}#post-meta time,#recent-posts time{display:inline!important}</style></noscript><script>(e=>{e.saveToLocal={set:function(e,t,a){0!==a&&(a=864e5*a,t={value:t,expiry:(new Date).getTime()+a},localStorage.setItem(e,JSON.stringify(t)))},get:function(e){var t=localStorage.getItem(e);if(t){t=JSON.parse(t);if(!((new Date).getTime()>t.expiry))return t.value;localStorage.removeItem(e)}}},e.getScript=o=>new Promise((t,e)=>{const a=document.createElement("script");a.src=o,a.async=!0,a.onerror=e,a.onload=a.onreadystatechange=function(){var e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(a.onload=a.onreadystatechange=null,t())},document.head.appendChild(a)}),e.getCSS=(o,n=!1)=>new Promise((t,e)=>{const a=document.createElement("link");a.rel="stylesheet",a.href=o,n&&(a.id=n),a.onerror=e,a.onload=a.onreadystatechange=function(){var e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(a.onload=a.onreadystatechange=null,t())},document.head.appendChild(a)}),e.activateDarkMode=function(){document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=function(){document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};e=saveToLocal.get("theme"),"dark"===e?activateDarkMode():"light"===e&&activateLightMode(),e=saveToLocal.get("aside-status");void 0!==e&&("hide"===e?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})(window)</script><meta name="generator" content="Hexo 6.0.0"></head><body><script>window.paceOptions={restartOnPushState:!1},document.addEventListener("pjax:send",()=>{Pace.restart()})</script><link rel="stylesheet" href="/assets/css/flash.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js"></script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://oss.kiscloud.net/image/user/anime/Chainsaw/qiu.webp" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">236</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">32</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">35</div></a></div><hr class="custom-hr"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/nav/"><i class="fa-fw fa fa-paper-plane"></i><span> 导航</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fa-fw fas fa-book"></i><span> 教程</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/python/"><i class="fa-fw fa-brands fa-python"></i><span> python教程</span></a></li><li><a class="site-page child" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"><i class="fa-fw fa-solid fa-database"></i><span> 大数据教程</span></a></li><li><a class="site-page child" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><i class="fa-fw fa-solid fa-desktop"></i><span> 机器学习教程</span></a></li><li><a class="site-page child" href="/DeepLearning/"><i class="fa-fw fas fa-video"></i><span> 深度学习教程</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fa-fw fas fa-list"></i><span> 娱乐</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="ihadu"><img class="site-icon" src="/images/sports.webp"></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/nav/"><i class="fa-fw fa fa-paper-plane"></i><span> 导航</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fa-fw fas fa-book"></i><span> 教程</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/python/"><i class="fa-fw fa-brands fa-python"></i><span> python教程</span></a></li><li><a class="site-page child" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"><i class="fa-fw fa-solid fa-database"></i><span> 大数据教程</span></a></li><li><a class="site-page child" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><i class="fa-fw fa-solid fa-desktop"></i><span> 机器学习教程</span></a></li><li><a class="site-page child" href="/DeepLearning/"><i class="fa-fw fas fa-video"></i><span> 深度学习教程</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fa-fw fas fa-list"></i><span> 娱乐</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">线性判别分析</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-08-27T10:02:16.000Z" title="发表于 2023-08-27 18:02:16">2023-08-27</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-08-28T08:20:44.191Z" title="更新于 2023-08-28 16:20:44">2023-08-28</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/">机器学习算法</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95/">降维算法</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">2.7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>14分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title="线性判别分析"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/posts/2b64aa80.html#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/posts/2b64aa80.html" itemprop="commentCount"><i class="fa-solid fa-spinner fa-spin"></i></span></a></span></div></div></div><article class="post-content" id="article-container"><h2 id="线性判别分析-Linear-Discriminant-Analysis">线性判别分析(Linear Discriminant Analysis)</h2><p>线性判别分析(Linear Discriminant Analysis)，是一种监督学习(supervised learning)算法。线性判别式分析也叫做Fisher线性判别(Fisher Linear Discriminant ,FLD)，是模式识别的经典算法，它是在1996年由Belhumeur引入模式识别和人工智能领域的。其鉴别分析的基本思想是将高维的模式样本投影到最佳鉴别矢量空间，以达到抽取分类信息和压缩特征空间维数的效果，投影后保证模式样本在新的子空间有最大的类间距离和最小的类内距离，即模式在该空间中有最佳的可分离性。因此，它是一种有效的特征抽取方法。使用这种方法能够使投影后模式样本的类间散布矩阵最大，并且同时类内散布矩阵最小。</p><p>线性判别分析(Linear Discriminant Analysis)是对费舍尔的线性鉴别方法的归纳，这种方法使用统计学，模式识别和机器学习方法，试图找到两类物体或事件的特征的一个线性组合，以能够特征化或区分它们。所得的组合可用来作为一个线性分类器，或者，更常见的是，为后续的分类做降维处理。</p><p>线性判别分析(Linear Discriminant Analysis)与方差分析（ANOVA）和回归分析紧密相关，这两种分析方法也试图通过一些特征或测量值的线性组合来表示一个因变量。然而，方差分析使用类别自变量和连续数因变量，而判别分析连续自变量和类别因变量（即类标签）。[3] 逻辑回归和概率回归比方差分析更类似于LDA，因为他们也是用连续自变量来解释类别因变量的。LDA的基本假设是自变量是正态分布的，当这一假设无法满足时，在实际应用中更倾向于用上述的其他方法。</p><p>线性判别分析(Linear Discriminant Analysis)也与主成分分析（PCA）和因子分析紧密相关，它们都在寻找最佳解释数据的变量线性组合。[4] LDA明确的尝试为数据类之间不同建立模型。 另一方面，PCA不考虑类的任何不同，因子分析是根据不同点而不是相同点来建立特征组合。判别的分析不同因子分析还在于，它不是一个相互依存技术：即必须区分出自变量和因变量（也称为准则变量）的不同。</p><p>在对自变量每一次观察测量值都是连续量的时候，LDA能有效的起作用。当处理类别自变量时，与LDA相对应的技术称为判别反应分析。</p><p>通常它能够保证投影后模式样本在新的空间中有最小的类内距离和最大的类间距离，即模式在该空间中有最佳的可分离性。</p><p>应用示例:</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> theano</span><br><span class="line"><span class="keyword">import</span> lasagne</span><br><span class="line"></span><br><span class="line"><span class="comment"># init color printer</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BColors</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Colored command line output formatting</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    HEADER = <span class="string">&#x27;\033[95m&#x27;</span></span><br><span class="line">    OKBLUE = <span class="string">&#x27;\033[94m&#x27;</span></span><br><span class="line">    OKGREEN = <span class="string">&#x27;\033[92m&#x27;</span></span><br><span class="line">    WARNING = <span class="string">&#x27;\033[93m&#x27;</span></span><br><span class="line">    FAIL = <span class="string">&#x27;\033[91m&#x27;</span></span><br><span class="line">    ENDC = <span class="string">&#x27;\033[0m&#x27;</span></span><br><span class="line">    BOLD = <span class="string">&#x27;\033[1m&#x27;</span></span><br><span class="line">    UNDERLINE = <span class="string">&#x27;\033[4m&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot; Constructor &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">print_colored</span>(<span class="params">self, string, color</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot; Change color of string &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> color + string + BColors.ENDC</span><br><span class="line"></span><br><span class="line">col = BColors()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">threaded_generator</span>(<span class="params">generator, num_cached=<span class="number">10</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Threaded generator</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">import</span> Queue</span><br><span class="line">    queue = Queue.Queue(maxsize=num_cached)</span><br><span class="line">    queue = Queue.Queue(maxsize=num_cached)</span><br><span class="line">    end_marker = <span class="built_in">object</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># define producer</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">producer</span>():</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> generator:</span><br><span class="line">            <span class="comment">#item = np.array(item)  # if needed, create a copy here</span></span><br><span class="line">            queue.put(item)</span><br><span class="line">        queue.put(end_marker)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># start producer</span></span><br><span class="line">    <span class="keyword">import</span> threading</span><br><span class="line">    thread = threading.Thread(target=producer)</span><br><span class="line">    thread.daemon = <span class="literal">True</span></span><br><span class="line">    thread.start()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># run as consumer</span></span><br><span class="line">    item = queue.get()</span><br><span class="line">    <span class="keyword">while</span> item <span class="keyword">is</span> <span class="keyword">not</span> end_marker:</span><br><span class="line">        <span class="keyword">yield</span> item</span><br><span class="line">        queue.task_done()</span><br><span class="line">        item = queue.get()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generator_from_iterator</span>(<span class="params">iterator</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compile generator from iterator</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> iterator:</span><br><span class="line">        <span class="keyword">yield</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">threaded_generator_from_iterator</span>(<span class="params">iterator, num_cached=<span class="number">10</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compile threaded generator from iterator</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    generator = generator_from_iterator(iterator)</span><br><span class="line">    <span class="keyword">return</span> threaded_generator(generator, num_cached)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">accuracy_score</span>(<span class="params">t, p</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute accuracy</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">float</span>(np.<span class="built_in">sum</span>(p == t)) / <span class="built_in">len</span>(p)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LDA</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; LDA Class &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, r=<span class="number">1e-3</span>, n_components=<span class="literal">None</span>, verbose=<span class="literal">False</span>, show=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot; Constructor &quot;&quot;&quot;</span></span><br><span class="line">        self.r = r</span><br><span class="line">        self.n_components = n_components</span><br><span class="line"></span><br><span class="line">        self.scalings_ = <span class="literal">None</span></span><br><span class="line">        self.coef_ = <span class="literal">None</span></span><br><span class="line">        self.intercept_ = <span class="literal">None</span></span><br><span class="line">        self.means = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        self.verbose = verbose</span><br><span class="line">        self.show = show</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, X, y, X_te=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot; Compute lda on hidden layer &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># split into semi- and supervised- data</span></span><br><span class="line">        X_all = X.copy()</span><br><span class="line">        X = X[y &gt;= <span class="number">0</span>]</span><br><span class="line">        y = y[y &gt;= <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># get class labels</span></span><br><span class="line">        classes = np.unique(y)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># set number of components</span></span><br><span class="line">        <span class="keyword">if</span> self.n_components <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            self.n_components = <span class="built_in">len</span>(classes) - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># compute means</span></span><br><span class="line">        means = []</span><br><span class="line">        <span class="keyword">for</span> group <span class="keyword">in</span> classes:</span><br><span class="line">            Xg = X[y == group, :]</span><br><span class="line">            means.append(Xg.mean(<span class="number">0</span>))</span><br><span class="line">        self.means = np.asarray(means)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># compute covs</span></span><br><span class="line">        covs = []</span><br><span class="line">        <span class="keyword">for</span> group <span class="keyword">in</span> classes:</span><br><span class="line">            Xg = X[y == group, :]</span><br><span class="line">            Xg = Xg - np.mean(Xg, axis=<span class="number">0</span>)</span><br><span class="line">            covs.append(np.cov(Xg.T))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># within scatter</span></span><br><span class="line">        Sw = np.average(covs, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># total scatter</span></span><br><span class="line">        X_all = X_all - np.mean(X_all, axis=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">if</span> X_te <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            St = np.cov(np.concatenate((X_all, X_te)).T)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            St = np.cov(X_all.T)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># between scatter</span></span><br><span class="line">        Sb = St - Sw</span><br><span class="line"></span><br><span class="line">        <span class="comment"># cope for numerical instability</span></span><br><span class="line">        Sw += np.identity(Sw.shape[<span class="number">0</span>]) * self.r</span><br><span class="line"></span><br><span class="line">        <span class="comment"># compute eigen decomposition</span></span><br><span class="line">        <span class="keyword">from</span> scipy.linalg.decomp <span class="keyword">import</span> eigh</span><br><span class="line">        evals, evecs = eigh(Sb, Sw)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># sort eigen vectors according to eigen values</span></span><br><span class="line">        evecs = evecs[:, np.argsort(evals)[::-<span class="number">1</span>]]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># normalize eigen vectors</span></span><br><span class="line">        evecs /= np.apply_along_axis(np.linalg.norm, <span class="number">0</span>, evecs)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># compute lda data</span></span><br><span class="line">        self.scalings_ = evecs</span><br><span class="line">        self.coef_ = np.dot(self.means, evecs).dot(evecs.T)</span><br><span class="line">        self.intercept_ = (-<span class="number">0.5</span> * np.diag(np.dot(self.means, self.coef_.T)))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.verbose:</span><br><span class="line">            top_k_evals = evals[-self.n_components:]</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;LDA-Eigenvalues (Train):&quot;</span>, np.array_str(top_k_evals, precision=<span class="number">2</span>, suppress_small=<span class="literal">True</span>))</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Ratio min(eigval)/max(eigval): %.3f, Mean(eigvals): %.3f&quot;</span> % (top_k_evals.<span class="built_in">min</span>() / top_k_evals.<span class="built_in">max</span>(), top_k_evals.mean()))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.show:</span><br><span class="line">            plt.figure(<span class="string">&quot;Eigenvalues&quot;</span>)</span><br><span class="line">            ax = plt.subplot(<span class="number">111</span>)</span><br><span class="line">            top_k_evals /= np.<span class="built_in">sum</span>(top_k_evals)</span><br><span class="line">            plt.plot(<span class="built_in">range</span>(self.n_components), top_k_evals, <span class="string">&#x27;bo-&#x27;</span>)</span><br><span class="line">            plt.grid(<span class="string">&#x27;on&#x27;</span>)</span><br><span class="line">            plt.xlabel(<span class="string">&#x27;Eigenvalue&#x27;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">            plt.ylabel(<span class="string">&#x27;Explained Discriminative Variance&#x27;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">            plt.ylim([<span class="number">0.0</span>, <span class="number">1.05</span> * np.<span class="built_in">max</span>(top_k_evals)])</span><br><span class="line"></span><br><span class="line">            ax.tick_params(axis=<span class="string">&#x27;x&#x27;</span>, labelsize=<span class="number">18</span>)</span><br><span class="line">            ax.tick_params(axis=<span class="string">&#x27;y&#x27;</span>, labelsize=<span class="number">18</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> evals</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">transform</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot; transform data &quot;&quot;&quot;</span></span><br><span class="line">        X_new = np.dot(X, self.scalings_)</span><br><span class="line">        <span class="keyword">return</span> X_new[:, :self.n_components]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict_proba</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot; estimate probability &quot;&quot;&quot;</span></span><br><span class="line">        prob = -(np.dot(X, self.coef_.T) + self.intercept_)</span><br><span class="line">        np.exp(prob, prob)</span><br><span class="line">        prob += <span class="number">1</span></span><br><span class="line">        np.reciprocal(prob, prob)</span><br><span class="line">        prob /= prob.<span class="built_in">sum</span>(axis=<span class="number">1</span>).reshape((prob.shape[<span class="number">0</span>], -<span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> prob</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict_log_proba</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot; estimate log probability &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> np.log(self.predict_proba(X))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_iter_functions</span>(<span class="params">l_out, l_in, y_tensor_type, objective, learning_rate, l_2, compute_updates</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Create functions for training, validation and testing to iterate one epoch. &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># init target tensor</span></span><br><span class="line">    targets = y_tensor_type(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute train costs</span></span><br><span class="line">    tr_output = lasagne.layers.get_output(l_out, deterministic=<span class="literal">False</span>)</span><br><span class="line">    tr_cost = objective(tr_output, targets)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute validation costs</span></span><br><span class="line">    va_output = lasagne.layers.get_output(l_out, deterministic=<span class="literal">True</span>)</span><br><span class="line">    va_cost = objective(va_output, targets)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># collect all parameters of net and compute updates</span></span><br><span class="line">    all_params = lasagne.layers.get_all_params(l_out, trainable=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># add weight decay</span></span><br><span class="line">    <span class="keyword">if</span> l_2 <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        tr_cost += l_2 * lasagne.regularization.apply_penalty(all_params, lasagne.regularization.l2)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute updates from gradients</span></span><br><span class="line">    all_grads = lasagne.updates.get_or_compute_grads(tr_cost, all_params)</span><br><span class="line">    updates = compute_updates(all_grads, all_params, learning_rate)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compile iter functions</span></span><br><span class="line">    tr_outputs = [tr_cost]</span><br><span class="line">    iter_train = theano.function([l_in.input_var, targets], tr_outputs, updates=updates)</span><br><span class="line"></span><br><span class="line">    va_outputs = [va_cost, va_output]</span><br><span class="line">    iter_valid = theano.function([l_in.input_var, targets], va_outputs)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compile output function</span></span><br><span class="line">    compute_output = theano.function([l_in.input_var], va_output)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">dict</span>(train=iter_train, valid=iter_valid, test=iter_valid, compute_output=compute_output)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">iter_funcs, dataset, train_batch_iter, valid_batch_iter, r</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Train the model with `dataset` with mini-batch training.</span></span><br><span class="line"><span class="string">    Each mini-batch has `batch_size` recordings.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">import</span> sys</span><br><span class="line">    <span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> itertools.count(<span class="number">1</span>):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># iterate train batches</span></span><br><span class="line">        batch_train_losses = []</span><br><span class="line">        iterator = train_batch_iter(dataset[<span class="string">&#x27;X_train&#x27;</span>], dataset[<span class="string">&#x27;y_train&#x27;</span>])</span><br><span class="line">        generator = threaded_generator_from_iterator(iterator)</span><br><span class="line"></span><br><span class="line">        start, after = time.time(), time.time()</span><br><span class="line">        <span class="keyword">for</span> i_batch, (X_b, y_b) <span class="keyword">in</span> <span class="built_in">enumerate</span>(generator):</span><br><span class="line">            batch_res = iter_funcs[<span class="string">&#x27;train&#x27;</span>](X_b, y_b)</span><br><span class="line">            batch_train_losses.append(batch_res[<span class="number">0</span>])</span><br><span class="line">            after = time.time()</span><br><span class="line">            train_time = (after-start)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># report loss during training</span></span><br><span class="line">            perc = <span class="number">100</span> * (<span class="built_in">float</span>(i_batch) / train_batch_iter.n_batches)</span><br><span class="line">            dec = <span class="built_in">int</span>(perc // <span class="number">4</span>)</span><br><span class="line">            progbar = <span class="string">&quot;|&quot;</span> + dec * <span class="string">&quot;#&quot;</span> + (<span class="number">25</span>-dec) * <span class="string">&quot;-&quot;</span> + <span class="string">&quot;|&quot;</span></span><br><span class="line">            vals = (perc, progbar, train_time, np.mean(batch_train_losses))</span><br><span class="line">            loss_str = <span class="string">&quot; (%d%%) %s time: %.2fs, loss: %.5f&quot;</span> % vals</span><br><span class="line">            <span class="built_in">print</span>(col.print_colored(loss_str, col.WARNING), end=<span class="string">&quot;\r&quot;</span>)</span><br><span class="line">            sys.stdout.flush()</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\x1b[K&quot;</span>, end=<span class="string">&quot;\r&quot;</span>)</span><br><span class="line">        avg_train_loss = np.mean(batch_train_losses)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># lda evaluation (accuracy based)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># iterate validation batches</span></span><br><span class="line">        batch_valid_losses = []</span><br><span class="line">        iterator = valid_batch_iter(dataset[<span class="string">&#x27;X_valid&#x27;</span>], dataset[<span class="string">&#x27;y_valid&#x27;</span>])</span><br><span class="line">        generator = threaded_generator_from_iterator(iterator)</span><br><span class="line">        net_output_va, y_va = <span class="literal">None</span>, np.zeros(<span class="number">0</span>, dtype=np.int32)</span><br><span class="line">        <span class="keyword">for</span> X_b, y_b <span class="keyword">in</span> generator:</span><br><span class="line">            batch_res = iter_funcs[<span class="string">&#x27;valid&#x27;</span>](X_b, y_b)</span><br><span class="line">            batch_valid_losses.append(batch_res[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">            y_va = np.concatenate((y_va, y_b))</span><br><span class="line">            net_output = iter_funcs[<span class="string">&#x27;compute_output&#x27;</span>](X_b)</span><br><span class="line">            <span class="keyword">if</span> net_output_va <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                net_output_va = net_output</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                net_output_va = np.vstack((net_output_va, net_output))</span><br><span class="line"></span><br><span class="line">        avg_valid_loss = np.mean(batch_valid_losses)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># compute train set net output</span></span><br><span class="line">        iterator = train_batch_iter(dataset[<span class="string">&#x27;X_train&#x27;</span>], dataset[<span class="string">&#x27;y_train&#x27;</span>])</span><br><span class="line">        generator = threaded_generator_from_iterator(iterator)</span><br><span class="line">        net_output_tr, y_tr = <span class="literal">None</span>, np.zeros(<span class="number">0</span>, dtype=np.int32)</span><br><span class="line">        <span class="keyword">for</span> i_batch, (X_b, y_b) <span class="keyword">in</span> <span class="built_in">enumerate</span>(generator):</span><br><span class="line">            y_tr = np.concatenate((y_tr, y_b))</span><br><span class="line">            net_output = iter_funcs[<span class="string">&#x27;compute_output&#x27;</span>](X_b)</span><br><span class="line">            <span class="keyword">if</span> net_output_tr <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                net_output_tr = net_output</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                net_output_tr = np.vstack((net_output_tr, net_output))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># fit lda on net output</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;&quot;</span>)</span><br><span class="line">        dlda = LDA(r=r, n_components=<span class="literal">None</span>, verbose=<span class="literal">True</span>)</span><br><span class="line">        evals = dlda.fit(net_output_tr, y_tr)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># predict on train set</span></span><br><span class="line">        proba = dlda.predict_proba(net_output_tr[y_tr &gt;= <span class="number">0</span>])</span><br><span class="line">        y_tr_pr = np.argmax(proba, axis=<span class="number">1</span>)</span><br><span class="line">        tr_acc = <span class="number">100</span> * accuracy_score(y_tr[y_tr &gt;= <span class="number">0</span>], y_tr_pr)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># predict on validation set</span></span><br><span class="line">        proba = dlda.predict_proba(net_output_va)</span><br><span class="line">        y_va_pr = np.argmax(proba, axis=<span class="number">1</span>)</span><br><span class="line">        va_acc = <span class="number">100</span> * accuracy_score(y_va, y_va_pr)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># estimate overfitting</span></span><br><span class="line">        overfit = va_acc / tr_acc</span><br><span class="line"></span><br><span class="line">        <span class="comment"># collect results</span></span><br><span class="line">        <span class="keyword">yield</span> &#123;</span><br><span class="line">            <span class="string">&#x27;number&#x27;</span>: epoch,</span><br><span class="line">            <span class="string">&#x27;train_loss&#x27;</span>: avg_train_loss,</span><br><span class="line">            <span class="string">&#x27;train_acc&#x27;</span>: tr_acc,</span><br><span class="line">            <span class="string">&#x27;valid_loss&#x27;</span>: avg_valid_loss,</span><br><span class="line">            <span class="string">&#x27;valid_acc&#x27;</span>: va_acc,</span><br><span class="line">            <span class="string">&#x27;overfitting&#x27;</span>: overfit,</span><br><span class="line">            <span class="string">&#x27;eigenvalues&#x27;</span>: evals</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">l_out, l_in, data, objective, y_tensor_type,</span></span><br><span class="line"><span class="params">        train_batch_iter, valid_batch_iter,</span></span><br><span class="line"><span class="params">        r=<span class="number">1e-3</span>, num_epochs=<span class="number">100</span>, patience=<span class="number">20</span>,</span></span><br><span class="line"><span class="params">        learn_rate=<span class="number">0.01</span>, update_learning_rate=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">        l_2=<span class="literal">None</span>, compute_updates=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">        exp_name=<span class="string">&#x27;ff&#x27;</span>, out_path=<span class="literal">None</span>, dump_file=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot; Train model &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># log model evolution</span></span><br><span class="line">    log_file = os.path.join(out_path, <span class="string">&#x27;results.pkl&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(col.print_colored(<span class="string">&quot;Running Test Case: &quot;</span> + exp_name, BColors.UNDERLINE))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># adaptive learning rate</span></span><br><span class="line">    learning_rate = theano.shared(np.float32(learn_rate))</span><br><span class="line">    <span class="keyword">if</span> update_learning_rate <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">update_learning_rate</span>(<span class="params">lr, e</span>):</span><br><span class="line">            <span class="keyword">return</span> lr</span><br><span class="line">    learning_rate.set_value(update_learning_rate(learn_rate, <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># initialize evaluation output</span></span><br><span class="line">    pred_tr_err, pred_val_err, overfitting = [], [], []</span><br><span class="line">    tr_accs, va_accs = [], []</span><br><span class="line">    eigenvalues = []</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Building model and compiling functions...&quot;</span>)</span><br><span class="line">    iter_funcs = create_iter_functions(l_out, l_in, y_tensor_type, objective, learning_rate=learning_rate,</span><br><span class="line">                                       l_2=l_2, compute_updates=compute_updates)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Starting training...&quot;</span>)</span><br><span class="line">    now = time.time()</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line"></span><br><span class="line">        <span class="comment"># initialize early stopping</span></span><br><span class="line">        last_improvement = <span class="number">0</span></span><br><span class="line">        best_model = lasagne.layers.get_all_param_values(l_out)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># iterate training epochs</span></span><br><span class="line">        prev_acc_tr, prev_acc_va = <span class="number">0.0</span>, <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> train(iter_funcs, data, train_batch_iter, valid_batch_iter, r):</span><br><span class="line"></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Epoch &#123;&#125; of &#123;&#125; took &#123;:.3f&#125;s&quot;</span>.<span class="built_in">format</span>(</span><br><span class="line">                epoch[<span class="string">&#x27;number&#x27;</span>], num_epochs, time.time() - now))</span><br><span class="line">            now = time.time()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># update learning rate</span></span><br><span class="line">            learn_rate = update_learning_rate(learn_rate, epoch[<span class="string">&#x27;number&#x27;</span>])</span><br><span class="line">            learning_rate.set_value(learn_rate)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># --- collect train output ---</span></span><br><span class="line"></span><br><span class="line">            tr_loss, va_loss = epoch[<span class="string">&#x27;train_loss&#x27;</span>], epoch[<span class="string">&#x27;valid_loss&#x27;</span>]</span><br><span class="line">            train_acc, valid_acc = epoch[<span class="string">&#x27;train_acc&#x27;</span>], epoch[<span class="string">&#x27;valid_acc&#x27;</span>]</span><br><span class="line">            overfit = epoch[<span class="string">&#x27;overfitting&#x27;</span>]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># prepare early stopping</span></span><br><span class="line">            <span class="keyword">if</span> valid_acc &gt;= prev_acc_va:</span><br><span class="line">                last_improvement = <span class="number">0</span></span><br><span class="line">                best_model = lasagne.layers.get_all_param_values(l_out)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># dump net parameters during training</span></span><br><span class="line">                <span class="keyword">if</span> dump_file <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    <span class="keyword">with</span> <span class="built_in">open</span>(dump_file, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">                        params = lasagne.layers.get_all_param_values(l_out)</span><br><span class="line">                        pickle.dump(params, fp)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># increase improvement counter</span></span><br><span class="line">            last_improvement += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># plot train output</span></span><br><span class="line">            <span class="keyword">if</span> train_acc <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                txt_tr = <span class="string">&#x27;costs_tr %.5f&#x27;</span> % tr_loss</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                txt_tr = <span class="string">&#x27;costs_tr %.5f (%.3f), &#x27;</span> % (tr_loss, train_acc)</span><br><span class="line">            <span class="keyword">if</span> train_acc &gt;= prev_acc_tr:</span><br><span class="line">                txt_tr = col.print_colored(txt_tr, BColors.OKGREEN)</span><br><span class="line">                prev_acc_tr = train_acc</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> valid_acc <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                txt_val = <span class="string">&#x27;&#x27;</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                txt_val = <span class="string">&#x27;costs_val %.5f (%.3f), tr/val %.3f&#x27;</span> % (va_loss, valid_acc, overfit)</span><br><span class="line">            <span class="keyword">if</span> valid_acc &gt;= prev_acc_va:</span><br><span class="line">                txt_val = col.print_colored(txt_val, BColors.OKGREEN)</span><br><span class="line">                prev_acc_va = valid_acc</span><br><span class="line"></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;  lr: %.5f&#x27;</span> % learn_rate)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;  &#x27;</span> + txt_tr + txt_val)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># collect model evolution data</span></span><br><span class="line">            tr_accs.append(train_acc)</span><br><span class="line">            va_accs.append(valid_acc)</span><br><span class="line">            pred_tr_err.append(tr_loss)</span><br><span class="line">            pred_val_err.append(va_loss)</span><br><span class="line">            overfitting.append(overfit)</span><br><span class="line">            eigenvalues.append(epoch[<span class="string">&#x27;eigenvalues&#x27;</span>])</span><br><span class="line"></span><br><span class="line">            <span class="comment"># --- early stopping: preserve best model ---</span></span><br><span class="line">            <span class="keyword">if</span> last_improvement &gt; patience:</span><br><span class="line">                <span class="built_in">print</span>(col.print_colored(<span class="string">&quot;Early Stopping!&quot;</span>, BColors.WARNING))</span><br><span class="line">                status = <span class="string">&quot;Epoch: %d, Best Validation Accuracy: %.3f&quot;</span> % (epoch[<span class="string">&#x27;number&#x27;</span>], prev_acc_va)</span><br><span class="line">                <span class="built_in">print</span>(col.print_colored(status, BColors.WARNING))</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># maximum number of epochs reached</span></span><br><span class="line">            <span class="keyword">if</span> epoch[<span class="string">&#x27;number&#x27;</span>] &gt;= num_epochs:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># shuffle train data</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">hasattr</span>(data[<span class="string">&#x27;X_train&#x27;</span>], <span class="string">&#x27;reset_batch_generator&#x27;</span>):</span><br><span class="line">                rand_idx = np.random.permutation(data[<span class="string">&#x27;X_train&#x27;</span>].shape[<span class="number">0</span>])</span><br><span class="line">                data[<span class="string">&#x27;X_train&#x27;</span>] = data[<span class="string">&#x27;X_train&#x27;</span>][rand_idx]</span><br><span class="line">                data[<span class="string">&#x27;y_train&#x27;</span>] = data[<span class="string">&#x27;y_train&#x27;</span>][rand_idx]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># save results</span></span><br><span class="line">            exp_res = <span class="built_in">dict</span>()</span><br><span class="line">            exp_res[<span class="string">&#x27;pred_tr_err&#x27;</span>] = pred_tr_err</span><br><span class="line">            exp_res[<span class="string">&#x27;tr_accs&#x27;</span>] = tr_accs</span><br><span class="line">            exp_res[<span class="string">&#x27;pred_val_err&#x27;</span>] = pred_val_err</span><br><span class="line">            exp_res[<span class="string">&#x27;va_accs&#x27;</span>] = va_accs</span><br><span class="line">            exp_res[<span class="string">&#x27;overfitting&#x27;</span>] = overfitting</span><br><span class="line">            exp_res[<span class="string">&#x27;eigenvalues&#x27;</span>] = eigenvalues</span><br><span class="line"></span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(log_file, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">                pickle.dump(exp_res, fp)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">except</span> KeyboardInterrupt:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># set net to best weights</span></span><br><span class="line">    lasagne.layers.set_all_param_values(l_out, best_model)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># evaluate on test set</span></span><br><span class="line">    test_losses, test_acc = [], []</span><br><span class="line">    iterator = valid_batch_iter(data[<span class="string">&#x27;X_test&#x27;</span>], data[<span class="string">&#x27;y_test&#x27;</span>])</span><br><span class="line">    <span class="keyword">for</span> X_b, y_b <span class="keyword">in</span> iterator:</span><br><span class="line">        loss_te = iter_funcs[<span class="string">&#x27;test&#x27;</span>](X_b, y_b)</span><br><span class="line">        test_losses.append(loss_te[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(loss_te) &gt; <span class="number">1</span>:</span><br><span class="line">            test_acc.append(loss_te[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute evaluation measures</span></span><br><span class="line">    avg_loss_te = np.mean(test_losses)</span><br><span class="line">    avg_acc_te = np.mean(test_acc)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;--------------------------------------------&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Loss on Test-Set: %.5f&#x27;</span> % avg_loss_te)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;--------------------------------------------\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> out_path <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line"></span><br><span class="line">        <span class="comment"># add test results and save results</span></span><br><span class="line">        exp_res[<span class="string">&#x27;avg_loss_te&#x27;</span>] = avg_loss_te</span><br><span class="line">        exp_res[<span class="string">&#x27;avg_acc_te&#x27;</span>] = avg_acc_te</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(log_file, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> fp:</span><br><span class="line">            pickle.dump(exp_res, fp)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> l_out, prev_acc_va</span><br></pre></td></tr></table></figure><blockquote><p>原文：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/KeKe-Li/tutorial">https://github.com/KeKe-Li/tutorial</a></p></blockquote></article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E9%99%8D%E7%BB%B4/">降维</a></div><div class="post_share"><div class="social-share" data-image="https://oss.kiscloud.net/image/user/anime/Chainsaw/wallhaven-gpjg37_1920x1080.webp" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/butterfly-extsrc/1.1.3/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdnjs.cloudflare.com/ajax/libs/butterfly-extsrc/1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/images/wechat.jpg" target="_blank"><img class="post-qr-code-img" src="/images/wechat.jpg" alt="wechat"></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="/images/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/images/alipay.jpg" alt="alipay"></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/2b210ebb.html" title="等度量映射"><img class="cover" src="https://oss.kiscloud.net/image/user/anime/Chainsaw/wallhaven-rr793m_1920x1080.webp" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">等度量映射</div></div></a></div><div class="next-post pull-right"><a href="/posts/47b1cb3a.html" title="多维缩放"><img class="cover" src="https://oss.kiscloud.net/image/user/anime/Chainsaw/wallhaven-1kgz11_1920x1080.webp" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">多维缩放</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/c7795c7c.html" title="降维与度量学习"><img class="cover" src="https://oss.kiscloud.net/image/user/anime/Chainsaw/wallhaven-1pk22g_1920x1080.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-08-25</div><div class="title">降维与度量学习</div></div></a></div><div><a href="/posts/dcf0690e.html" title="t－分布随机近邻嵌入"><img class="cover" src="https://oss.kiscloud.net/image/user/anime/Cyberpunk/wallhaven-7pg1m9_2880x1800.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-08-27</div><div class="title">t－分布随机近邻嵌入</div></div></a></div><div><a href="/posts/7276e58.html" title="主成分分析"><img class="cover" src="https://oss.kiscloud.net/image/user/anime/Chainsaw/wallhaven-5gdjr8_1920x1080.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-08-27</div><div class="title">主成分分析</div></div></a></div><div><a href="/posts/4e25b259.html" title="局部线性嵌入"><img class="cover" src="https://oss.kiscloud.net/image/user/anime/Chainsaw/wallhaven-gpjg37_1920x1080.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-08-27</div><div class="title">局部线性嵌入</div></div></a></div><div><a href="/posts/47b1cb3a.html" title="多维缩放"><img class="cover" src="https://oss.kiscloud.net/image/user/anime/Chainsaw/wallhaven-1kgz11_1920x1080.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-08-27</div><div class="title">多维缩放</div></div></a></div><div><a href="/posts/3a7a5673.html" title="拉普拉斯特征映射"><img class="cover" src="https://oss.kiscloud.net/image/user/anime/Chainsaw/wallhaven-m3gjpm_1920x1080.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-08-27</div><div class="title">拉普拉斯特征映射</div></div></a></div></div></div><hr class="custom-hr"><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://oss.kiscloud.net/image/user/anime/Chainsaw/qiu.webp" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info__name">ihadu</div><div class="author-info__description">黑暗中大雪纷飞的人</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">236</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">32</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">35</div></a></div><a id="card-info-btn" target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/ihadu"><i class="fab fa-github"></i><span>look Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/ihadu" rel="external nofollow noreferrer" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:ihadyou@qq.com" rel="external nofollow noreferrer" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://weibo.com/u/5992742619" rel="external nofollow noreferrer" target="_blank"><i class="fa-brands fa-weibo"></i></a><a class="social-icon" href="https://www.cnblogs.com/ihadu/post-categories/#/c/subject/category/default.html" rel="external nofollow noreferrer" target="_blank"><i class="fa-solid fa-blog"></i></a><a class="social-icon" href="/nav/" target="_blank"><i class="fa fa-paper-plane"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">Have you found your way home yet</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90-Linear-Discriminant-Analysis"><span class="toc-number">1.</span> <span class="toc-text">线性判别分析(Linear Discriminant Analysis)</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/c9036b1c.html" title="人工智能中的搜索算法"><img src="https://oss.kiscloud.net/image/user/anime/Chainsaw/wallhaven-1pk851_1920x1080.webp" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="人工智能中的搜索算法"></a><div class="content"><a class="title" href="/posts/c9036b1c.html" title="人工智能中的搜索算法">人工智能中的搜索算法</a><time datetime="2023-09-06T11:34:15.000Z" title="发表于 2023-09-06 19:34:15">2023-09-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/549bc4b6.html" title="深入解读 MongoDB CDC 的设计与实现"><img src="https://oss.kiscloud.net/image/user/anime/Chainsaw/wallhaven-rr7ldm_1920x1080.webp" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="深入解读 MongoDB CDC 的设计与实现"></a><div class="content"><a class="title" href="/posts/549bc4b6.html" title="深入解读 MongoDB CDC 的设计与实现">深入解读 MongoDB CDC 的设计与实现</a><time datetime="2023-09-04T14:38:54.000Z" title="发表于 2023-09-04 22:38:54">2023-09-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/4121201d.html" title="Java 8 并发教程：原子变量和 ConcurrentMap"><img src="https://oss.kiscloud.net/image/user/anime/Chainsaw/wallhaven-vqm6qm_1920x1080.webp" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Java 8 并发教程：原子变量和 ConcurrentMap"></a><div class="content"><a class="title" href="/posts/4121201d.html" title="Java 8 并发教程：原子变量和 ConcurrentMap">Java 8 并发教程：原子变量和 ConcurrentMap</a><time datetime="2023-08-29T09:19:26.000Z" title="发表于 2023-08-29 17:19:26">2023-08-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/4c4d17bf.html" title="Java 8 并发教程：同步和锁"><img src="https://oss.kiscloud.net/image/user/anime/Chainsaw/wallhaven-l8qxqy_1920x1080.webp" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Java 8 并发教程：同步和锁"></a><div class="content"><a class="title" href="/posts/4c4d17bf.html" title="Java 8 并发教程：同步和锁">Java 8 并发教程：同步和锁</a><time datetime="2023-08-29T09:17:57.000Z" title="发表于 2023-08-29 17:17:57">2023-08-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/7e39f321.html" title="Java 8 并发教程：线程和执行器"><img src="https://oss.kiscloud.net/image/user/anime/Chainsaw/wallhaven-vqd9qm_1920x1080.webp" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Java 8 并发教程：线程和执行器"></a><div class="content"><a class="title" href="/posts/7e39f321.html" title="Java 8 并发教程：线程和执行器">Java 8 并发教程：线程和执行器</a><time datetime="2023-08-29T09:15:52.000Z" title="发表于 2023-08-29 17:15:52">2023-08-29</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2024 By ihadu</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text"><img src="https://haiyong.site/img/icp.png"><a href="https://beian.miit.gov.cn/#/Integrated/index" rel="external nofollow noreferrer" style="color:#fff" target="_blank">皖ICP备19024061号-4</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.19/fancybox/fancybox.umd.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.2.0/instantpage.min.js" type="module"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/node-snackbar/0.1.16/snackbar.min.js"></script><script>function panguFn(){"object"==typeof pangu?pangu.autoSpacingPage():getScript("https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js").then(()=>{pangu.autoSpacingPage()})}function panguInit(){GLOBAL_CONFIG_SITE.isPost&&panguFn()}document.addEventListener("DOMContentLoaded",panguInit)</script><div class="js-pjax"><script>function loadValine(){function n(){new Valine(Object.assign({el:"#vcomment",appId:"kriIEcS9Jj1uTpNoV1sFu2Rk-gzGzoHsz",appKey:"mnmRNJ7HtlpE7664tpn7Kfmy",avatar:"monsterid",serverURLs:"",emojiMaps:"",path:window.location.pathname,visitor:!1},null))}"function"==typeof Valine?n():getScript("https://cdnjs.cloudflare.com/ajax/libs/valine/1.5.1/Valine.min.js").then(n)}function loadOtherComment(){loadValine()}setTimeout(loadValine,0)</script></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdnjs.cloudflare.com/ajax/libs/butterfly-extsrc/1.1.3/fireworks.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/butterfly-extsrc/1.1.3/activate-power-mode.min.js"></script><script>POWERMODE.colorful=!0,POWERMODE.shake=!0,POWERMODE.mobile=!0,document.body.addEventListener("input",POWERMODE)</script><script src="https://cdnjs.cloudflare.com/ajax/libs/pjax/0.2.8/pjax.min.js"></script><script>let pjaxSelectors=["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"];var pjax=new Pjax({elements:'a:not([target="_blank"]):not([href="/music/"])',selectors:pjaxSelectors,cacheBust:!1,analytics:!1,scrollRestoration:!1});document.addEventListener("pjax:send",function(){if(window.tocScrollFn&&window.removeEventListener("scroll",window.tocScrollFn),window.scrollCollect&&window.removeEventListener("scroll",scrollCollect),document.getElementById("rightside").style.cssText="opacity: ''; transform: ''",window.aplayers)for(let e=0;e<window.aplayers.length;e++)window.aplayers[e].options.fixed||window.aplayers[e].destroy();"object"==typeof typed&&typed.destroy();var e=document.body.classList;e.contains("read-mode")&&e.remove("read-mode"),"object"==typeof disqusjs&&disqusjs.destroy()}),document.addEventListener("pjax:complete",function(){window.refreshFn(),document.querySelectorAll("script[data-pjax]").forEach(e=>{const t=document.createElement("script");var o=e.text||e.textContent||e.innerHTML||"";Array.from(e.attributes).forEach(e=>t.setAttribute(e.name,e.value)),t.appendChild(document.createTextNode(o)),e.parentNode.replaceChild(t,e)}),GLOBAL_CONFIG.islazyload&&window.lazyLoadInstance.update(),"function"==typeof panguInit&&panguInit(),"function"==typeof gtag&&gtag("config","",{page_path:window.location.pathname}),"object"==typeof _hmt&&_hmt.push(["_trackPageview",window.location.pathname]),"function"==typeof loadMeting&&document.getElementsByClassName("aplayer").length&&loadMeting(),"object"==typeof Prism&&Prism.highlightAll()}),document.addEventListener("pjax:error",e=>{404===e.request.status&&pjax.loadUrl("/404.html")})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span> 数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,debug:!1,model:{scale:1,hHeadPos:.5,vHeadPos:.618,jsonPath:"/live2d_models/gun/95type_405/normal/model.json"},display:{superSample:2,position:"left",width:200,height:400,hOffset:30,vOffset:-80},mobile:{show:!1,scale:1},react:{opacityDefault:.3,opacityOnHover:.3,opacity:.95},dialog:{enable:!0,hitokoto:!0},log:!1})</script></body></html>